---
layout: page
title: Hi, I'm Yanwu Xu
subtitle: PhD student in Artificial Intellegence
use-site-title: true
---

<h3>Short Bio</h3>
<p>Hi, here is Yanwu Xu, currently a 5th-year PhD student in ECE department at 
  Boston Univeristy, advised by <a href="https://kayhan.dbmi.pitt.edu">Dr. Kayhan Batmanghelich</a>. I am also a 
part-time student researcher at Google. Before that, I obtained the M.S. degree in the Intelligent System Program at the University of Pittsburgh in 2022.</p>
  
My current research interests are <b>Generative Model </b>, which includes the fundamental study of <b>Denoising Diffusion models<b> and <b>Generative Adversarial Learning</b>. For the application,
I am focusing on the large-scale multimodal generative models of text-to-image generation in both the computer vision and medical imaging domains. With Google, we are creating the next-generation
efficient on-device human-centred AI applications.


<h3>Blog</h3>
<ul>
  <li><p>Congrats on our fundamental generative model accepted by NeurIPS. In this work, we proposed a novel Denoising Diffusion models with GANs. <br/>
    
    
Despite the proliferation of generative models, achieving fast sampling during
inference without compromising sample diversity and quality remains challenging.
Existing models such as Denoising Diffusion Probabilistic Models (DDPM) deliver
high-quality, diverse samples but are slowed by an inherently high number of iterative steps. The Denoising Diffusion Generative Adversarial Networks (DDGAN)
attempted to circumvent this limitation by integrating a GAN model for larger
jumps in the diffusion process. However, DDGAN encountered scalability limitations when applied to large datasets. To address these limitations, we introduce a
novel approach that tackles the problem by matching implicit and explicit factors.
More specifically, our approach involves utilizing an implicit model to match the
marginal distributions of noisy data and the explicit conditional distribution of
the forward diffusion. This combination allows us to effectively match the joint
denoising distributions. Unlike DDPM but similar to DDGAN, we do not enforce
a parametric distribution for the reverse step, enabling us to take large steps during
inference. Similar to the DDPM but unlike DDGAN, we take advantage of the
exact form of the diffusion process. We demonstrate that our proposed method
obtains comparable generative performance to diffusion-based models and vastly
superior results to models with a small number of sampling steps.
    
</ul>


<h3>News</h3>
<ul>
  <li><p>One paper accepted by <b>NeurIPS2023</b>.</p></li>
  <li><p>One paper accepted by <b>ICCV2023</b>.</p></li>
  <li><p>One paper accepted by <b>MICCAI2022</b>.</p></li>
  <li><p>I will start my 2022 summer internship at <b>Google</b>.</p></li>
  <li><p>One papers is accepted by <b>CVPR 2022</b>.</p></li>
  <li><p>One papers is accepted by <b>ACM 2021</b>.</p></li>
  <li><p>One papers is accepted by <b>ICCV 2021</b>.</p></li>
  <li><p>Two papers are accepted by <b>AAAI 2020</b>.</p></li>
  <li><p>One paper is accepted by <b>NeurIPS 2019</b>.</p></li>
  <li><p>One paper is accepted by <b>BraTS Challenge 2018</b>.</p></li>
  <li><p>One paper is accepted by <b>ACCV 2018</b>.</p></li>
</ul>

